{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqiPQS2xJa7Q"
      },
      "source": [
        "# Sustainability Report Parser\n",
        "\n",
        "This file is created in order to create a parser that automatically extracts out the ESG data from tables in sustainability reports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "LdfVSyes-J8Y"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "%pip install llama-index-embeddings-openai\n",
        "%pip install llama-index-llms-openai\n",
        "%pip install llama-index-core llama-parse\n",
        "%pip install llama-index-core llama-parse llama-index-readers-file python-dotenv\n",
        "%pip install llama-index-program-openai\n",
        "%pip install -U llama-index llama-index-vector-stores-qdrant fastembed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apaG8L_vJY9K"
      },
      "source": [
        "OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EqzsJXtVJYC-"
      },
      "outputs": [],
      "source": [
        "# If using OpenAI LLMs to get keywords\n",
        "import os\n",
        "import openai\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] =\n",
        "\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.schema import MetadataMode\n",
        "\n",
        "llm = OpenAI(temperature=0.1, model=\"gpt-4o-mini\", max_tokens=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GieUrAHrJoHx"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "EMBEDDING_MODEL  = \"text-embedding-3-small\"\n",
        "embed_model = OpenAIEmbedding(model=EMBEDDING_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0wBGkqFKMi5"
      },
      "source": [
        "LLama parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "WKiRt4JYKNpt",
        "outputId": "11280bfb-b8a5-4f29-df71-919a514955ca"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "No files found in /content.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9461c383286c>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mfile_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\".xlsx\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleDirectoryReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_extractor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_extractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/readers/file/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dir, input_files, exclude, exclude_hidden, errors, recursive, encoding, filename_as_id, required_exts, file_extractor, num_files_limit, file_metadata, raise_on_error, fs)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexclude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile_extractor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/core/readers/file/base.py\u001b[0m in \u001b[0;36m_add_files\u001b[0;34m(self, input_dir)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_input_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No files found in {input_dir}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_files_limit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_files_limit\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No files found in /content."
          ]
        }
      ],
      "source": [
        "# Uncomment if you are in a Jupyter Notebook\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "#PLEASE RUN ONLY ONCE, 1k pages/day\n",
        "\n",
        "from llama_parse import LlamaParse  # pip install llama-parse\n",
        "from llama_index.core import SimpleDirectoryReader  # pip install llama-index\n",
        "\n",
        "parse_instructions = '''This xlsx contains the ESG performace of Norilsk Nickels.  It contains many tables. Always ensure that a column representing the year of disclosure has a value in every row. If no values are found, replace it with NA. Answer questions using the tables found in this document and be precise.'''\n",
        "\n",
        "parser = LlamaParse(\n",
        "    api_key=,  # can also be set in your env as LLAMA_CLOUD_API_KEY\n",
        "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
        "    parsing_instruction= parse_instructions,\n",
        ")\n",
        "\n",
        "file_extractor = {\".xlsx\": parser}\n",
        "reader = SimpleDirectoryReader(\"/content\", file_extractor=file_extractor)\n",
        "documents = reader.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9vspjboJMCg"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
        "\n",
        "# Parse the documents using MarkdownElementNodeParser\n",
        "node_parser = MarkdownElementNodeParser(llm=llm, num_workers=8).from_defaults()\n",
        "\n",
        "# Retrieve nodes (text) and objects (table)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "\n",
        "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm6mvhPWVOvT"
      },
      "source": [
        "Pydantic model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMrRM4CzWdaV"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "\n",
        "from llama_index.program.openai import OpenAIPydanticProgram\n",
        "\n",
        "\n",
        "class Fact(BaseModel):\n",
        "  \"\"\"Sustainability Fact\"\"\"\n",
        "\n",
        "  unit: str\n",
        "  value: float\n",
        "  year: int\n",
        "\n",
        "class Metric(BaseModel):\n",
        "  \"\"\"Sustainability Metric\"\"\"\n",
        "\n",
        "  values: List[Fact]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et5kkCB40U_o"
      },
      "source": [
        "Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIjgTMyG0UZX"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex, StorageContext\n",
        "from llama_index.core import Settings\n",
        "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
        "from google.colab import userdata\n",
        "import qdrant_client\n",
        "\n",
        "client = qdrant_client.QdrantClient(\n",
        "    # otherwise set Qdrant instance address with:\n",
        "    url= \"https://af77da8c-504c-4c06-8140-407b89986d03.europe-west3-0.gcp.cloud.qdrant.io:6333\",\n",
        "    # set API KEY for Qdrant Cloud\n",
        "    api_key= userdata.get('Qdrant'),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idq9xvR32Tmg"
      },
      "outputs": [],
      "source": [
        "# create our vector store with hybrid indexing enabled\n",
        "# batch_size controls how many nodes are encoded with sparse vectors at once\n",
        "vector_store = QdrantVectorStore(\n",
        "    \"Sustainability_Report_Parser_Test1\",\n",
        "    # client=client,\n",
        "    # aclient=aclient,\n",
        "    enable_hybrid=True,\n",
        "    api_key = userdata.get('Qdrant'),\n",
        "    url=\"https://af77da8c-504c-4c06-8140-407b89986d03.europe-west3-0.gcp.cloud.qdrant.io:6333\"\n",
        ")\n",
        "\n",
        "#combine both into storage contect\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "index = VectorStoreIndex(nodes = base_nodes + objects, storage_context=storage_context)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HNx0PrUs_cuY"
      },
      "outputs": [],
      "source": [
        "objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4XoV2RbJZpN"
      },
      "outputs": [],
      "source": [
        "# one extra dep\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# create an index from the parsed markdown\n",
        "#index = VectorStoreIndex.from_documents(documents)\n",
        "index = VectorStoreIndex(\n",
        "    nodes= base_nodes + objects\n",
        ")\n",
        "\n",
        "#create a query engine for the index\n",
        "\n",
        "query_engine = index.as_query_engine(similarity_top_k = 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfTpTrrBDODU"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "Extract the number of strikes and lockouts in this report. This data can be found from a table.\n",
        "\n",
        "Please provide a structure response with the following JSON schema:\n",
        "{\n",
        "  \"values\" : [Fact]\n",
        "}\n",
        "\n",
        "Where each fact has the following JSON schema:\n",
        "{\n",
        "  \"unit\": \"string\"\n",
        "  \"value\": \"float\"\n",
        "  \"year\": \"integer\"\n",
        "}\n",
        "\n",
        "If you cannot find the data, please return an empty dictionary in the form of {}. If any of the values are not present, please return None.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHlBcKpfDQ57"
      },
      "outputs": [],
      "source": [
        "retriever = index.as_retriever()\n",
        "retrieved_nodes = retriever.retrieve(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3Ha0q0pDdq9"
      },
      "outputs": [],
      "source": [
        "print(retrieved_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmvTopRdbFma"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Atao0kEbOH_d"
      },
      "outputs": [],
      "source": [
        "print(response.response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7lIfcWPC4Eo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "pd.DataFrame(json.loads(response.response)['values'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi_4HvwoXb3l"
      },
      "outputs": [],
      "source": [
        "query_engine.get_prompts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfy3X41C8SeB"
      },
      "source": [
        "Define a prompt viewing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plfHfk198NAC"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# define prompt viewing function\n",
        "def display_prompt_dict(prompts_dict):\n",
        "    for k, p in prompts_dict.items():\n",
        "        text_md = f\"**Prompt Key**: {k}\" f\"**Text:** \"\n",
        "        display(Markdown(text_md))\n",
        "        print(p.get_template())\n",
        "        display(Markdown(\"\"))\n",
        "\n",
        "prompts_dict = query_engine.get_prompts()\n",
        "\n",
        "display_prompt_dict(prompts_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnBYd0yaRQym"
      },
      "source": [
        "Prompts to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hfvqt2kF8dsh"
      },
      "outputs": [],
      "source": [
        "def make_prompt(metric):\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "\n",
        "  Extract the {metric} in this report. This data can be found from a table.\n",
        "  \"\"\" + \"\"\"\n",
        "\n",
        "  Please provide a structure response with the following JSON schema:\n",
        "  {\n",
        "    \"values\" : [Fact]\n",
        "  }\n",
        "\n",
        "  Where each fact has the following JSON schema:\n",
        "  {\n",
        "    \"year\": \"integer\"\n",
        "    \"value\": \"float\"\n",
        "    \"unit\": \"string\"\n",
        "  }\n",
        "\n",
        "  If you cannot find the data, please return an empty dictionary in the form of {}. If any of the values are not present, please return None.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjxLNSwyUlti"
      },
      "source": [
        "Reading in SASB standards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XZqjjiTRyEh"
      },
      "outputs": [],
      "source": [
        "indicators_base = pd.read_csv('Main Database - Indicator Names.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sQXZrAGTr7L"
      },
      "outputs": [],
      "source": [
        "metric_list = [\n",
        "    #GHG Emissions\n",
        "    \"total gross global scope 1 emissions\",\n",
        "    \"total percentage of gross global scope 1 emissions under emissions-limiting regulations\",\n",
        "    #Air Quality\n",
        "    \"total CO emissions\",\n",
        "    \"total NOx emissions\",\n",
        "    \"total SOx emissions\",\n",
        "    \"total PM10 emissions\",\n",
        "    \"total mercury (HG) emissions\",\n",
        "    \"total lead (PB) emissions\",\n",
        "    \"total volatile organic compounds (VOCs) emissions\",\n",
        "    #Energy Management\n",
        "    \"total energy consumed\",\n",
        "    \"total renewable energy consumed\",\n",
        "    \"total energy consumed from grid electricity\",\n",
        "    \"percentage energy consumed from grid electricity\",\n",
        "    \"percentage energy consumed from renewable electricity\",\n",
        "    #Water Management\n",
        "    \"total freshwater withdrawn\",\n",
        "    \"total freshwater consumed\",\n",
        "    \"total water withdrawn in high or extremely high baseline water stress areas\",\n",
        "    \"total water consumed in high or extremely high baseline water stress areas\",\n",
        "    \"percentage of water withdrawn in high or extremely high baseline water stress areas against total freshwater withdrawn\",\n",
        "    \"percentage of water consumed in high or extremely high baseline water stress areas against total freshwater consumed\",\n",
        "    \"number of incidents of non-compliance associated with water quality permits, standards, and regulations\",\n",
        "    #Waste Management\n",
        "    \"total weight of tailing waste\",\n",
        "    \"total weight of tailing waste recylced\",\n",
        "    \"percentage of tailing waste recylced\",\n",
        "    \"total weight of mineral waste\",\n",
        "    \"total weight of mineral waste recylced\",\n",
        "    \"percentage of mineral waste recylced\",\n",
        "    \"number of tailing impoundments\", #broken down by msha hazard potential <- need to add this\n",
        "    #Biodiversity Impacts\n",
        "    \"number of mine sites where acid rock drainage is predicted to occur\",\n",
        "    \"percentage of total mine sites where acid rock drainage is predicted to occur\",\n",
        "    \"number of mine sites where acid rock drainage is actively mitigated\",\n",
        "    \"percentage of total mine sites where acid rock drainage is actively mitigated\",\n",
        "    \"number of mine sites where acid rock drainage is under treatment or remediation\",\n",
        "    \"percentage of total mine sites where acid rock drainage is under treatment or remediation\",\n",
        "    \"total area of proved reserves in or near sites with protected conservation status or endangered species habitat\",\n",
        "    \"percentage of total area of proved reserves in or near sites with protected conservation status or endangered species habitat\",\n",
        "    \"total area of probable reserves in or near sites with protected conservation status or endangered species habitat\",\n",
        "    \"percentage of total area of probable reserves in or near sites with protected conservation status or endangered species habitat\",\n",
        "    #Human Rights\n",
        "    \"total area of proved reserves in or near areas of conflict\",\n",
        "    \"percentage of total area of proved reserves in or near areas of conflict\",\n",
        "    \"total area of probable reserves in or near areas of conflict\",\n",
        "    \"percentage of total area of probable reserves in or near areas of conflict\",\n",
        "    \"total area of proved reserves in or near indigenous land\",\n",
        "    \"percentage of total area of proved reserves in or near indigenous land\",\n",
        "    \"total area of probable reserves in or near indigenous land\",\n",
        "    \"percentage of total area of probable reserves in or near indigenous land\",\n",
        "    #Community Relations\n",
        "    \"number of non-technical delays\",\n",
        "    \"duration of non-technical delays\",\n",
        "    #Labour Relations\n",
        "    \"total number of employees covered under collective bargaining agreements\",\n",
        "    \"total number of contractors covered under collective bargaining agreements\",\n",
        "    \"percentage of employees covered under collective bargaining agreements\",\n",
        "    \"percentage of contractors covered under collective bargaining agreements\",\n",
        "    \"number of strikes and lockouts\",\n",
        "    \"duration of strikes and lockouts\",\n",
        "    #Workforce Health and Safety\n",
        "    \"total number of MHSA incidents\",\n",
        "    \"total MSHA all-incidents rate\",\n",
        "    \"total number of fatalities\",\n",
        "    \"total fatality rate\",\n",
        "    \"total number of near misses\",\n",
        "    \"total near miss frequecy rate (NMFR)\",\n",
        "    \"average hours of health, safety and emergency response training for full time employees\",\n",
        "    \"average hours of health, safety and emergency response training for contract employees\",\n",
        "    #Business Ethics and Transparency\n",
        "    \"production in countries that have the 20 lowest rankings in Transparency International's Corruption Perception Index\",\n",
        "    #Activity Metrics\n",
        "    \"total number of employees\",\n",
        "    \"total number of contractors\",\n",
        "    \"percentage of employees who are contractors\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5SJWgS3C-qc"
      },
      "outputs": [],
      "source": [
        "SASB_ind_dict = {\n",
        "    #GHG Emissions\n",
        "    \"total gross global scope 1 emissions\":\"Gross global Scope 1 emissions, percentage covered under emissions-limiting regulations\",\n",
        "    \"total percentage of gross global scope 1 emissions under emissions-limiting regulations\":\"Gross global Scope 1 emissions, percentage covered under emissions-limiting regulations\",\n",
        "    #Air Quality\n",
        "    \"total CO emissions\":\"Air emissions of the following pollutants: (1) CO, (2) NOx (excluding N2O), (3) SOx, (4) particulate matter (PM10), (5) mercury (Hg), (6) lead (Pb), and (7) volatile organic compounds (VOCs)\",\n",
        "    \"total NOx emissions\":\"Air emissions of the following pollutants: (1) CO, (2) NOx (excluding N2O), (3) SOx, (4) particulate matter (PM10), (5) mercury (Hg), (6) lead (Pb), and (7) volatile organic compounds (VOCs)\",\n",
        "    \"total SOx emissions\":\"Air emissions of the following pollutants: (1) CO, (2) NOx (excluding N2O), (3) SOx, (4) particulate matter (PM10), (5) mercury (Hg), (6) lead (Pb), and (7) volatile organic compounds (VOCs)\",\n",
        "    \"total PM10 emissions\":\"Air emissions of the following pollutants: (1) CO, (2) NOx (excluding N2O), (3) SOx, (4) particulate matter (PM10), (5) mercury (Hg), (6) lead (Pb), and (7) volatile organic compounds (VOCs)\",\n",
        "    \"total mercury (HG) emissions\":\"Air emissions of the following pollutants: (1) CO, (2) NOx (excluding N2O), (3) SOx, (4) particulate matter (PM10), (5) mercury (Hg), (6) lead (Pb), and (7) volatile organic compounds (VOCs)\",\n",
        "    \"total lead (PB) emissions\":\"Air emissions of the following pollutants: (1) CO, (2) NOx (excluding N2O), (3) SOx, (4) particulate matter (PM10), (5) mercury (Hg), (6) lead (Pb), and (7) volatile organic compounds (VOCs)\",\n",
        "    \"total volatile organic compounds (VOCs) emissions\":\"Air emissions of the following pollutants: (1) CO, (2) NOx (excluding N2O), (3) SOx, (4) particulate matter (PM10), (5) mercury (Hg), (6) lead (Pb), and (7) volatile organic compounds (VOCs)\",\n",
        "    #Energy Management\n",
        "    \"total energy consumed\":\"(1) Total energy consumed, (2) percentage grid electricity, (3) percentage renewable\",\n",
        "    \"total renewable energy consumed\":\"(1) Total energy consumed, (2) percentage grid electricity, (3) percentage renewable\",\n",
        "    \"total energy consumed from grid electricity\":\"(1) Total energy consumed, (2) percentage grid electricity, (3) percentage renewable\",\n",
        "    \"percentage energy consumed from grid electricity\":\"(1) Total energy consumed, (2) percentage grid electricity, (3) percentage renewable\",\n",
        "    \"percentage energy consumed from renewable electricity\":\"(1) Total energy consumed, (2) percentage grid electricity, (3) percentage renewable\",\n",
        "    #Water Management\n",
        "    \"total freshwater withdrawn\":\"(1) Total fresh water withdrawn, (2) total fresh water consumed, percentage of each in regions with High or Extremely High Baseline Water Stress\",\n",
        "    \"total freshwater consumed\":\"(1) Total fresh water withdrawn, (2) total fresh water consumed, percentage of each in regions with High or Extremely High Baseline Water Stress\",\n",
        "    \"total water withdrawn in high or extremely high baseline water stress areas\":\"(1) Total fresh water withdrawn, (2) total fresh water consumed, percentage of each in regions with High or Extremely High Baseline Water Stress\",\n",
        "    \"total water consumed in high or extremely high baseline water stress areas\":\"(1) Total fresh water withdrawn, (2) total fresh water consumed, percentage of each in regions with High or Extremely High Baseline Water Stress\",\n",
        "    \"percentage of water withdrawn in high or extremely high baseline water stress areas against total freshwater withdrawn\":\"(1) Total fresh water withdrawn, (2) total fresh water consumed, percentage of each in regions with High or Extremely High Baseline Water Stress\",\n",
        "    \"percentage of water consumed in high or extremely high baseline water stress areas against total freshwater consumed\":\"(1) Total fresh water withdrawn, (2) total fresh water consumed, percentage of each in regions with High or Extremely High Baseline Water Stress\",\n",
        "    \"number of incidents of non-compliance associated with water quality permits, standards, and regulations\":\"Number of incidents of non-compliance associated with water quality permits, standards, and regulations\",\n",
        "    #Waste Management\n",
        "    \"total weight of tailing waste\":\"Total weight of tailings waste, percentage recycled\",\n",
        "    \"total weight of tailing waste recylced\":\"Total weight of tailings waste, percentage recycled\",\n",
        "    \"percentage of tailing waste recylced\":\"Total weight of tailings waste, percentage recycled\",\n",
        "    \"total weight of mineral waste\":\"Total weight of mineral processing waste, percentage recycled\",\n",
        "    \"total weight of mineral waste recylced\":\"Total weight of mineral processing waste, percentage recycled\",\n",
        "    \"percentage of mineral waste recylced\":\"Total weight of mineral processing waste, percentage recycled\",\n",
        "    \"number of tailing impoundments\":\"Number of tailings impoundments, broken down by MSHA hazard potential\", #broken down by msha hazard potential <- need to add this\n",
        "    #Biodiversity Impacts\n",
        "    \"number of mine sites where acid rock drainage is predicted to occur\":\"Percentage of mine sites where acid rock drainage is: (1) predicted to occur, (2) actively mitigated, and (3) under treatment or remediation\",\n",
        "    \"percentage of total mine sites where acid rock drainage is predicted to occur\":\"Percentage of mine sites where acid rock drainage is: (1) predicted to occur, (2) actively mitigated, and (3) under treatment or remediation\",\n",
        "    \"number of mine sites where acid rock drainage is actively mitigated\":\"Percentage of mine sites where acid rock drainage is: (1) predicted to occur, (2) actively mitigated, and (3) under treatment or remediation\",\n",
        "    \"percentage of total mine sites where acid rock drainage is actively mitigated\":\"Percentage of mine sites where acid rock drainage is: (1) predicted to occur, (2) actively mitigated, and (3) under treatment or remediation\",\n",
        "    \"number of mine sites where acid rock drainage is under treatment or remediation\":\"Percentage of mine sites where acid rock drainage is: (1) predicted to occur, (2) actively mitigated, and (3) under treatment or remediation\",\n",
        "    \"percentage of total mine sites where acid rock drainage is under treatment or remediation\":\"Percentage of mine sites where acid rock drainage is: (1) predicted to occur, (2) actively mitigated, and (3) under treatment or remediation\",\n",
        "    \"total area of proved reserves in or near sites with protected conservation status or endangered species habitat\":\"Percentage of (1) proved and (2) probable reserves in or near sites with protected conservation status or endangered species habitat\",\n",
        "    \"percentage of total area of proved reserves in or near sites with protected conservation status or endangered species habitat\":\"Percentage of (1) proved and (2) probable reserves in or near sites with protected conservation status or endangered species habitat\",\n",
        "    \"total area of probable reserves in or near sites with protected conservation status or endangered species habitat\":\"Percentage of (1) proved and (2) probable reserves in or near sites with protected conservation status or endangered species habitat\",\n",
        "    \"percentage of total area of probable reserves in or near sites with protected conservation status or endangered species habitat\":\"Percentage of (1) proved and (2) probable reserves in or near sites with protected conservation status or endangered species habitat\",\n",
        "    #Human Rights\n",
        "    \"total area of proved reserves in or near areas of conflict\":\"Percentage of (1) proved and (2) probable reserves in or near areas of conflict\",\n",
        "    \"percentage of total area of proved reserves in or near areas of conflict\":\"Percentage of (1) proved and (2) probable reserves in or near areas of conflict\",\n",
        "    \"total area of probable reserves in or near areas of conflict\":\"Percentage of (1) proved and (2) probable reserves in or near areas of conflict\",\n",
        "    \"percentage of total area of probable reserves in or near areas of conflict\":\"Percentage of (1) proved and (2) probable reserves in or near areas of conflict\",\n",
        "    \"total area of proved reserves in or near indigenous land\":\"Percentage of (1) proved and (2) probable reserves in or near indigenous land\",\n",
        "    \"percentage of total area of proved reserves in or near indigenous land\":\"Percentage of (1) proved and (2) probable reserves in or near indigenous land\",\n",
        "    \"total area of probable reserves in or near indigenous land\":\"Percentage of (1) proved and (2) probable reserves in or near indigenous land\",\n",
        "    \"percentage of total area of probable reserves in or near indigenous land\":\"Percentage of (1) proved and (2) probable reserves in or near indigenous land\",\n",
        "    #Community Relations\n",
        "    \"number of non-technical delays\":\"Number and duration of non-technical delays\",\n",
        "    \"duration of non-technical delays\":\"Number and duration of non-technical delays\",\n",
        "    #Labour Relations\n",
        "    \"total number of employees covered under collective bargaining agreements\":\"Percentage of active workforce covered under collective bargaining agreements, broken down by U.S. and foreign employees\",\n",
        "    \"total number of contractors covered under collective bargaining agreements\":\"Percentage of active workforce covered under collective bargaining agreements, broken down by U.S. and foreign employees\",\n",
        "    \"percentage of employees covered under collective bargaining agreements\":\"Percentage of active workforce covered under collective bargaining agreements, broken down by U.S. and foreign employees\",\n",
        "    \"percentage of contractors covered under collective bargaining agreements\":\"Percentage of active workforce covered under collective bargaining agreements, broken down by U.S. and foreign employees\",\n",
        "    \"number of strikes and lockouts\":\"Number and duration of strikes and lockouts\",\n",
        "    \"duration of strikes and lockouts\":\"Number and duration of strikes and lockouts\",\n",
        "    #Workforce Health and Safety\n",
        "    \"total number of MHSA incidents\":\"(1) MSHA all-incidence rate, (2) fatality rate, (3) near miss frequency rate (NMFR) and (4) average hours of health, safety, and emergency response training for (a) full-time employees and (b) contract employees\",\n",
        "    \"total MSHA all-incidents rate\":\"(1) MSHA all-incidence rate, (2) fatality rate, (3) near miss frequency rate (NMFR) and (4) average hours of health, safety, and emergency response training for (a) full-time employees and (b) contract employees\",\n",
        "    \"total number of fatalities\":\"(1) MSHA all-incidence rate, (2) fatality rate, (3) near miss frequency rate (NMFR) and (4) average hours of health, safety, and emergency response training for (a) full-time employees and (b) contract employees\",\n",
        "    \"total fatality rate\":\"(1) MSHA all-incidence rate, (2) fatality rate, (3) near miss frequency rate (NMFR) and (4) average hours of health, safety, and emergency response training for (a) full-time employees and (b) contract employees\",\n",
        "    \"total number of near misses\":\"(1) MSHA all-incidence rate, (2) fatality rate, (3) near miss frequency rate (NMFR) and (4) average hours of health, safety, and emergency response training for (a) full-time employees and (b) contract employees\",\n",
        "    \"total near miss frequecy rate (NMFR)\":\"(1) MSHA all-incidence rate, (2) fatality rate, (3) near miss frequency rate (NMFR) and (4) average hours of health, safety, and emergency response training for (a) full-time employees and (b) contract employees\",\n",
        "    \"average hours of health, safety and emergency response training for full time employees\":\"(1) MSHA all-incidence rate, (2) fatality rate, (3) near miss frequency rate (NMFR) and (4) average hours of health, safety, and emergency response training for (a) full-time employees and (b) contract employees\",\n",
        "    \"average hours of health, safety and emergency response training for contract employees\":\"(1) MSHA all-incidence rate, (2) fatality rate, (3) near miss frequency rate (NMFR) and (4) average hours of health, safety, and emergency response training for (a) full-time employees and (b) contract employees\",\n",
        "    #Business Ethics and Transparency\n",
        "    \"production in countries that have the 20 lowest rankings in Transparency International's Corruption Perception Index\":\"Production in countries that have the 20 lowest rankings in Transparency International’s Corruption Perception Index\",\n",
        "    #Activity Metrics\n",
        "    \"total number of employees\":\"Total number of employees, percentage contractors\",\n",
        "    \"total number of contractors\":\"Total number of employees, percentage contractors\",\n",
        "    \"percentage of employees who are contractors\":\"Total number of employees, percentage contractors\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNxPzQueGC9B"
      },
      "outputs": [],
      "source": [
        "SASB_code_dict = {\n",
        "    #GHG Emissions\n",
        "    \"total gross global scope 1 emissions\":\"EM-MM-110a.1\",\n",
        "    \"total percentage of gross global scope 1 emissions under emissions-limiting regulations\":\"EM-MM-110a.1\",\n",
        "    #Air Quality\n",
        "    \"total CO emissions\":\"EM-MM-120a.1\",\n",
        "    \"total NOx emissions\":\"EM-MM-120a.1\",\n",
        "    \"total SOx emissions\":\"EM-MM-120a.1\",\n",
        "    \"total PM10 emissions\":\"EM-MM-120a.1\",\n",
        "    \"total mercury (HG) emissions\":\"EM-MM-120a.1\",\n",
        "    \"total lead (PB) emissions\":\"EM-MM-120a.1\",\n",
        "    \"total volatile organic compounds (VOCs) emissions\":\"EM-MM-120a.1\",\n",
        "    #Energy Management\n",
        "    \"total energy consumed\":\"EM-MM-130a.1\",\n",
        "    \"total renewable energy consumed\":\"EM-MM-130a.1\",\n",
        "    \"total energy consumed from grid electricity\":\"EM-MM-130a.1\",\n",
        "    \"percentage energy consumed from grid electricity\":\"EM-MM-130a.1\",\n",
        "    \"percentage energy consumed from renewable electricity\":\"EM-MM-130a.1\",\n",
        "    #Water Management\n",
        "    \"total freshwater withdrawn\":\"EM-MM-140a.1\",\n",
        "    \"total freshwater consumed\":\"EM-MM-140a.1\",\n",
        "    \"total water withdrawn in high or extremely high baseline water stress areas\":\"EM-MM-140a.1\",\n",
        "    \"total water consumed in high or extremely high baseline water stress areas\":\"EM-MM-140a.1\",\n",
        "    \"percentage of water withdrawn in high or extremely high baseline water stress areas against total freshwater withdrawn\":\"EM-MM-140a.1\",\n",
        "    \"percentage of water consumed in high or extremely high baseline water stress areas against total freshwater consumed\":\"EM-MM-140a.1\",\n",
        "    \"number of incidents of non-compliance associated with water quality permits, standards, and regulations\":\"EM-MM-140a.2\",\n",
        "    #Waste Management\n",
        "    \"total weight of tailing waste\":\"EM-MM-150a.1\",\n",
        "    \"total weight of tailing waste recylced\":\"EM-MM-150a.1\",\n",
        "    \"percentage of tailing waste recylced\":\"EM-MM-150a.1\",\n",
        "    \"total weight of mineral waste\":\"EM-MM-150a.2\",\n",
        "    \"total weight of mineral waste recylced\":\"EM-MM-150a.2\",\n",
        "    \"percentage of mineral waste recylced\":\"EM-MM-150a.2\",\n",
        "    \"number of tailing impoundments\":\"EM-MM-150a.3\", #broken down by msha hazard potential <- need to add this\n",
        "    #Biodiversity Impacts\n",
        "    \"number of mine sites where acid rock drainage is predicted to occur\":\"EM-MM-160a.2\",\n",
        "    \"percentage of total mine sites where acid rock drainage is predicted to occur\":\"EM-MM-160a.2\",\n",
        "    \"number of mine sites where acid rock drainage is actively mitigated\":\"EM-MM-160a.2\",\n",
        "    \"percentage of total mine sites where acid rock drainage is actively mitigated\":\"EM-MM-160a.2\",\n",
        "    \"number of mine sites where acid rock drainage is under treatment or remediation\":\"EM-MM-160a.2\",\n",
        "    \"percentage of total mine sites where acid rock drainage is under treatment or remediation\":\"EM-MM-160a.2\",\n",
        "    \"total area of proved reserves in or near sites with protected conservation status or endangered species habitat\":\"EM-MM-160a.3\",\n",
        "    \"percentage of total area of proved reserves in or near sites with protected conservation status or endangered species habitat\":\"EM-MM-160a.3\",\n",
        "    \"total area of probable reserves in or near sites with protected conservation status or endangered species habitat\":\"EM-MM-160a.3\",\n",
        "    \"percentage of total area of probable reserves in or near sites with protected conservation status or endangered species habitat\":\"EM-MM-160a.3\",\n",
        "    #Human Rights\n",
        "    \"total area of proved reserves in or near areas of conflict\":\"EM-MM-210a.1\",\n",
        "    \"percentage of total area of proved reserves in or near areas of conflict\":\"EM-MM-210a.1\",\n",
        "    \"total area of probable reserves in or near areas of conflict\":\"EM-MM-210a.1\",\n",
        "    \"percentage of total area of probable reserves in or near areas of conflict\":\"EM-MM-210a.1\",\n",
        "    \"total area of proved reserves in or near indigenous land\":\"EM-MM-210a.2\",\n",
        "    \"percentage of total area of proved reserves in or near indigenous land\":\"EM-MM-210a.2\",\n",
        "    \"total area of probable reserves in or near indigenous land\":\"EM-MM-210a.2\",\n",
        "    \"percentage of total area of probable reserves in or near indigenous land\":\"EM-MM-210a.2\",\n",
        "    #Community Relations\n",
        "    \"number of non-technical delays\":\"EM-MM-210b.2\",\n",
        "    \"duration of non-technical delays\":\"EM-MM-210b.2\",\n",
        "    #Labour Relations\n",
        "    \"total number of employees covered under collective bargaining agreements\":\"EM-MM-310a.1\",\n",
        "    \"total number of contractors covered under collective bargaining agreements\":\"EM-MM-310a.1\",\n",
        "    \"percentage of employees covered under collective bargaining agreements\":\"EM-MM-310a.1\",\n",
        "    \"percentage of contractors covered under collective bargaining agreements\":\"EM-MM-310a.1\",\n",
        "    \"number of strikes and lockouts\":\"EM-MM-310a.2\",\n",
        "    \"duration of strikes and lockouts\":\"EM-MM-310a.2\",\n",
        "    #Workforce Health and Safety\n",
        "    \"total number of MHSA incidents\":\"EM-MM-320a.1\",\n",
        "    \"total MSHA all-incidents rate\":\"EM-MM-320a.1\",\n",
        "    \"total number of fatalities\":\"EM-MM-320a.1\",\n",
        "    \"total fatality rate\":\"EM-MM-320a.1\",\n",
        "    \"total number of near misses\":\"EM-MM-320a.1\",\n",
        "    \"total near miss frequecy rate (NMFR)\":\"EM-MM-320a.1\",\n",
        "    \"average hours of health, safety and emergency response training for full time employees\":\"EM-MM-320a.1\",\n",
        "    \"average hours of health, safety and emergency response training for contract employees\":\"EM-MM-320a.1\",\n",
        "    #Business Ethics and Transparency\n",
        "    \"production in countries that have the 20 lowest rankings in Transparency International's Corruption Perception Index\":\"EM-MM-510a.2\",\n",
        "    #Activity Metrics\n",
        "    \"total number of employees\":\"EM-MM-000.B\",\n",
        "    \"total number of contractors\":\"EM-MM-000.B\",\n",
        "    \"percentage of employees who are contractors\":\"EM-MM-000.B\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElY9v7-5xNqR"
      },
      "outputs": [],
      "source": [
        "def extracted_info(metric):\n",
        "  query = make_prompt(metric)\n",
        "  response = query_engine.query(query)\n",
        "  return response.response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI8ZP1WCuyyi"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import concurrent.futures\n",
        "\n",
        "# Using ThreadPoolExecutor to create a list in parallel\n",
        "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "    # Map the function to the inputs in parallel\n",
        "    results = list(tqdm(executor.map(extracted_info, metric_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15PllHqjNH-4"
      },
      "outputs": [],
      "source": [
        "print(results[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17agBr-2yNYJ"
      },
      "outputs": [],
      "source": [
        "def write_df(results):\n",
        "  df = pd.DataFrame()\n",
        "  counter = 0\n",
        "\n",
        "  for result in results:\n",
        "    try:\n",
        "      result_df = pd.DataFrame(json.loads(result)['values'])\n",
        "    except:\n",
        "      pass\n",
        "    else:\n",
        "      num_entries = len(result_df)\n",
        "\n",
        "      if num_entries > 0:\n",
        "        metric = metric_list[counter]\n",
        "        result_df.insert(3, 'remarks', metric)\n",
        "        result_df.insert(0, 'indicator', SASB_code_dict[metric])\n",
        "        result_df.insert(1, 'indicator name', SASB_ind_dict[metric])\n",
        "        #result_df['remark'] = [metric] * num_entries\n",
        "        df = pd.concat([df,result_df], ignore_index=True)\n",
        "    counter += 1\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbxnyPqS3CTO"
      },
      "outputs": [],
      "source": [
        "df = write_df(results)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLh3v8B93Lfv"
      },
      "outputs": [],
      "source": [
        "df.to_csv('Norilsk Nickels data.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iArFuUwAOibl"
      },
      "source": [
        "Lets try pure chatgpt wout llama index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OtpIv9WPDEK"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "#When Creating the assistant for the first timme\n",
        "assistant = client.beta.assistants.create(\n",
        "  name=\"Albemarle Data Scraper\",\n",
        "  instructions=\n",
        "  \"\"\"You are an ESG data scraper for Albemarle, a chemical manufacturing company.\n",
        "  You will be provided a pdf file which contains many ESG tables. You will be tasked to extract out ESG information.\n",
        "\n",
        "  Please provide a structured response with the following JSON schema:\n",
        "  {\n",
        "    \"values\" : [Fact]\n",
        "  }\n",
        "\n",
        "  Where each fact has the following JSON schema:\n",
        "  {\n",
        "    \"year\": \"integer\"\n",
        "    \"value\": \"float\"\n",
        "    \"unit\": \"string\"\n",
        "  }\n",
        "\n",
        "  If you cannot find the data, please return an empty dictionary in the form of {}. If any of the values are not present, please return NA for that attribute.\n",
        "\n",
        "  \"\"\",\n",
        "  model=\"gpt-4o-mini\",\n",
        "  tools=[{\"type\": \"file_search\"}],\n",
        ")\n",
        "\n",
        "#assistant = client.beta.assistants.retrieve('asst_pbID5ew1pwi2PuqLkuLljS47')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1VnTlYcOqRz"
      },
      "outputs": [],
      "source": [
        "# Create a vector store caled \"{Company} ESG Statements\"\n",
        "vector_store = client.beta.vector_stores.create(name=\"Albermarle Databook\")\n",
        "\n",
        "# Ready the files for upload to OpenAI\n",
        "file_paths = [\"/content/Albemarle.pdf\"]\n",
        "file_streams = [open(path, \"rb\") for path in file_paths]\n",
        "\n",
        "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
        "# and poll the status of the file batch for completion.\n",
        "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
        "  vector_store_id=vector_store.id, files=file_streams\n",
        ")\n",
        "\n",
        "# You can print the status and the file counts of the batch to see the result of this operation.\n",
        "print(file_batch.status)\n",
        "print(file_batch.file_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hQ5QSYwgM3D"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.update(\n",
        "  assistant_id=assistant.id,\n",
        "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWVYeUq7Ot4o"
      },
      "outputs": [],
      "source": [
        "# Upload the user provided file to OpenAI\n",
        "message_file = client.files.create(\n",
        "  file=open(\"/content/Cameco Databook.pdf\", \"rb\"), purpose=\"assistants\"\n",
        ")\n",
        "\n",
        "# Create a thread and attach the file to the message\n",
        "thread = client.beta.threads.create(\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Extract the gross global scope 1 emissions in this report.\",\n",
        "      # Attach the new file to the message.\n",
        "      \"attachments\": [\n",
        "        {\"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
        "      ],\n",
        "    },\n",
        "  ]\n",
        ")\n",
        "\n",
        "# The thread now has a vector store with that file in its tool resources.\n",
        "print(thread.tool_resources.file_search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpkSnfbdOwGq"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import override\n",
        "from openai import AssistantEventHandler, OpenAI\n",
        "\n",
        "# client = OpenAI()\n",
        "\n",
        "class EventHandler(AssistantEventHandler):\n",
        "\n",
        "    # def on_text_created(self, text) -> None:\n",
        "    #     print(f\"\\nassistant > \", end=\"\", flush=True)\n",
        "\n",
        "    # def on_tool_call_created(self, tool_call):\n",
        "    #     print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
        "\n",
        "    @override\n",
        "    def on_message_done(self, message) -> None:\n",
        "        # print a citation to the file searched\n",
        "        message_content = message.content[0].text\n",
        "        annotations = message_content.annotations\n",
        "        citations = []\n",
        "        for index, annotation in enumerate(annotations):\n",
        "            message_content.value = message_content.value.replace(\n",
        "                annotation.text, f\"[{index}]\"\n",
        "            )\n",
        "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "                cited_file = client.files.retrieve(file_citation.file_id)\n",
        "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "        #print(message_content.value)\n",
        "        #print(\"\\n\".join(citations))\n",
        "\n",
        "\n",
        "# Then, we use the stream SDK helper\n",
        "# with the EventHandler class to create the Run\n",
        "# and stream the response.\n",
        "\n",
        "# with client.beta.threads.runs.stream(\n",
        "#     thread_id=thread.id,\n",
        "#     assistant_id=assistant.id,\n",
        "#     event_handler=EventHandler(),\n",
        "# ) as stream:\n",
        "#     stream.until_done()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnT0eHOUWEdj"
      },
      "outputs": [],
      "source": [
        "print(openai.beta.threads.messages.list(thread.id).data[0].content[0].text.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5wY-gnvWbNr"
      },
      "outputs": [],
      "source": [
        "txt = openai.beta.threads.messages.list(thread.id).data[0].content[0].text.value\n",
        "print(txt.split(\"```json\")[1].split(\"```\")[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sc7hG8CmZRYo"
      },
      "outputs": [],
      "source": [
        "def extract_info(prompt, assistant):\n",
        "\n",
        "  # assistant = client.beta.assistants.retrieve('asst_jlqE279HiI2fagr9Cg1wKUrO')\n",
        "\n",
        "  # vector_store = client.beta.vector_stores.retrieve('vs_33fCZa1x5FlcKr32bnjpOT6W')\n",
        "\n",
        "  # assistant = client.beta.assistants.update(\n",
        "  # assistant_id=assistant.id,\n",
        "  # tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
        "  # )\n",
        "\n",
        "  # Create a thread and attach the file to the message\n",
        "  thread = client.beta.threads.create(\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"Extract the {prompt} in this report.\",\n",
        "        # Attach the new file to the message.\n",
        "      },\n",
        "    ]\n",
        "  )\n",
        "  # assistant = assistant\n",
        "\n",
        "  with client.beta.threads.runs.stream(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id,\n",
        "    event_handler=EventHandler(),\n",
        "  ) as stream:\n",
        "    stream.until_done()\n",
        "\n",
        "  txt = openai.beta.threads.messages.list(thread.id).data[0].content[0].text.value\n",
        "  #print(openai.beta.threads.messages.list(thread.id))\n",
        "  return(txt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5lOpA34jhmx"
      },
      "outputs": [],
      "source": [
        "out = extract_info(\"the gross global scope 1 emissions\")\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcWbKxrIkHAt"
      },
      "outputs": [],
      "source": [
        "out.split(\"```json\")[1].split(\"```\")[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tZmcJVRfkbit"
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "# results = []\n",
        "\n",
        "# for metric in metric_list:\n",
        "#   results.append(extract_info(metric))\n",
        "\n",
        "\n",
        "\n",
        "# Using ThreadPoolExecutor to create a list in parallel\n",
        "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "    # Map the function to the inputs in parallel\n",
        "    results = list(tqdm(executor.map(extract_info, metric_list)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3G7-25ypEOK"
      },
      "outputs": [],
      "source": [
        "def get_json(outs):\n",
        "  final = []\n",
        "  for out in outs:\n",
        "    try:\n",
        "      split = out.split(\"```json\")[1].split(\"```\")[0]\n",
        "      final.append(split)\n",
        "    except:\n",
        "      final.append(out)\n",
        "  return final\n",
        "\n",
        "def write_df(results):\n",
        "\n",
        "  import pandas as pd\n",
        "  import json\n",
        "\n",
        "  df = pd.DataFrame()\n",
        "  counter = 0\n",
        "\n",
        "  for result in results:\n",
        "    try:\n",
        "      result_df = pd.DataFrame(json.loads(result)['values'])\n",
        "    except:\n",
        "      pass\n",
        "    else:\n",
        "      num_entries = len(result_df)\n",
        "\n",
        "      if num_entries > 0:\n",
        "        metric = metric_list[counter]\n",
        "        result_df.insert(3, 'remarks', metric)\n",
        "        result_df.insert(0, 'indicator', SASB_code_dict[metric])\n",
        "        result_df.insert(1, 'indicator name', SASB_ind_dict[metric])\n",
        "        #result_df['remark'] = [metric] * num_entries\n",
        "        df = pd.concat([df,result_df], ignore_index=True)\n",
        "    counter += 1\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDjvQnzbpXum"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "df = write_df(get_json(results))\n",
        "\n",
        "df.to_csv('Albemarle data 2.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eekZUlD01uRN"
      },
      "source": [
        "## Putting it all in 1 chunk for easier loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYfLKt1F1x30"
      },
      "outputs": [],
      "source": [
        "def parse_doc(company, company_desc, sus_report):\n",
        "\n",
        "  from openai import OpenAI\n",
        "\n",
        "  client = OpenAI()\n",
        "\n",
        "  #Create Assistant to scrape Data\n",
        "  assistant = client.beta.assistants.create(\n",
        "    name=f\"{company} Data Scraper\",\n",
        "    instructions=\n",
        "    f\"\"\"You are an ESG data scraper for {company}, a {company_desc}.\"\"\"\n",
        "     +\n",
        "    \"\"\"You will be provided a pdf file which contains many ESG tables. You will be tasked to extract out ESG information.\n",
        "\n",
        "    Please provide a structured response with the following JSON schema:\n",
        "    {\n",
        "      \"values\" : [Fact]\n",
        "    }\n",
        "\n",
        "    Where each fact has the following JSON schema:\n",
        "    {\n",
        "      \"year\": \"integer\"\n",
        "      \"value\": \"float\"\n",
        "      \"unit\": \"string\"\n",
        "    }\n",
        "\n",
        "    If you cannot find the data, please return an empty dictionary in the form of {}. If any of the values are not present, please return NA for that attribute.\n",
        "\n",
        "    \"\"\",\n",
        "    model=\"gpt-4o-mini\",\n",
        "    tools=[{\"type\": \"file_search\"}],\n",
        "  )\n",
        "\n",
        "\n",
        "  # Create a vector store caled \"{Company} Databook\"\n",
        "  vector_store = client.beta.vector_stores.create(name=f\"{company} Databook\")\n",
        "\n",
        "  # Ready the files for upload to OpenAI\n",
        "  file_paths = [sus_report]\n",
        "  file_streams = [open(path, \"rb\") for path in file_paths]\n",
        "\n",
        "  # Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
        "  # and poll the status of the file batch for completion.\n",
        "  file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
        "    vector_store_id=vector_store.id, files=file_streams\n",
        "  )\n",
        "\n",
        "  # You can print the status and the file counts of the batch to see the result of this operation.\n",
        "  # print(file_batch.status)\n",
        "  # print(file_batch.file_counts)\n",
        "\n",
        "  #Attach vector store to assistant\n",
        "  assistant = client.beta.assistants.update(\n",
        "    assistant_id=assistant.id,\n",
        "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
        "  )\n",
        "\n",
        "\n",
        "  import concurrent.futures\n",
        "  import time\n",
        "  from tqdm import tqdm\n",
        "\n",
        "  ass_list = [assistant] * len(metric_list)\n",
        "\n",
        "  # Using ThreadPoolExecutor to create a list in parallel\n",
        "  with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "      # Map the function to the inputs in parallel\n",
        "      results = list(tqdm(executor.map(extract_info, metric_list, ass_list)))\n",
        "\n",
        "  df = write_df(get_json(results))\n",
        "\n",
        "  df.to_csv(f'{company} data.csv', index = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbmH3qaR7pFu"
      },
      "outputs": [],
      "source": [
        "parse_doc(\"ComfortDelGro\",\"multi-national transport group\", \"/content/ComfortDelGro Sustainability Report 2023.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2n7zdHDCoDF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}